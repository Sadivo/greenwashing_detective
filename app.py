
import requests
from flask import Flask, render_template, request, jsonify, send_from_directory
import pymysql
from pymysql.cursors import DictCursor
import os
import json
from dotenv import load_dotenv
from src.calculate_esg import calculate_esg_scores
from config import PATHS

load_dotenv()

# ==============Flask éƒ¨åˆ†========================
app = Flask(__name__)

# === ğŸ†• è¨˜æ†¶é«”æ¨™è¨˜ï¼šè¿½è¹¤æ­£åœ¨æ´»èºè™•ç†ä¸­çš„å…¬å¸ ===
# æœå‹™é‡å•Ÿæ™‚æœƒæ¸…ç©ºï¼Œç”¨æ–¼å€åˆ†ã€Œæ´»èºè™•ç†ä¸­ã€å’Œã€Œä¸­æ–·éœ€æ¢å¾©ã€
import time
ACTIVE_PROCESSING = {}  # {esg_id: start_timestamp}

def cleanup_temp_files(year, company_code, company_name):
    """ç•¶æ•´å€‹æµç¨‹å®Œå…¨æˆåŠŸå¾Œï¼Œæ¸…ç†æ‰€æœ‰æš«å­˜ JSON èˆ‡ PDF"""
    file_targets = [
        # 1. ESG å ±å‘Š PDF
        os.path.join(PATHS['ESG_REPORTS'], f"{year}_{company_code}_{company_name}_æ°¸çºŒå ±å‘Šæ›¸.pdf"),
        
        # 2. Stage 2 ç”¢å‡ºçš„ P1 JSON
        os.path.join(PATHS['P1_JSON'], f"{year}_{company_code}_p1.json"),
        
        # 3. Stage 3 ç”¢å‡ºçš„ News JSON
        os.path.join(PATHS['NEWS_OUTPUT'], f"{year}_{company_code}_news.json"),
        
        # 4. Stage 4 ç”¢å‡ºçš„ P2 JSON
        os.path.join(PATHS['P2_JSON'], f"{year}_{company_code}_p2.json"),
        
        # 5. Stage 5 ç”¢å‡ºçš„ P3 JSON
        os.path.join(PATHS['P3_JSON'], f"{year}_{company_code}_p3.json"),
    ]
    
    print(f"ğŸ§¹ é–‹å§‹åŸ·è¡Œæœ€çµ‚æ¸…ç†æµç¨‹ ({year}_{company_code})...")
    for file_path in file_targets:
        try:
            if os.path.exists(file_path):
                os.remove(file_path)
                print(f"  âœ… å·²åˆªé™¤: {os.path.basename(file_path)}")
        except Exception as e:
            # ä½¿ç”¨ print æˆ– logging è¨˜éŒ„éŒ¯èª¤ï¼Œä½†ä¸ä¸­æ–·ä¸»ç¨‹å¼
            print(f"  âš ï¸ ç„¡æ³•åˆªé™¤ {file_path}: {e}")

def mark_processing_start(esg_id):
    """æ¨™è¨˜é–‹å§‹è™•ç†æŸå…¬å¸"""
    ACTIVE_PROCESSING[esg_id] = time.time()
    print(f"ğŸŸ¢ æ¨™è¨˜é–‹å§‹è™•ç†: {esg_id}")

def mark_processing_end(esg_id):
    """æ¨™è¨˜è™•ç†çµæŸï¼ˆå®Œæˆæˆ–å¤±æ•—ï¼‰"""
    if esg_id in ACTIVE_PROCESSING:
        del ACTIVE_PROCESSING[esg_id]
        print(f"ğŸ”´ æ¨™è¨˜è™•ç†çµæŸ: {esg_id}")

def is_actively_processing(esg_id):
    """æª¢æŸ¥æ˜¯å¦æ­£åœ¨æ´»èºè™•ç†ä¸­"""
    return esg_id in ACTIVE_PROCESSING


# --- è³‡æ–™åº«é€£ç·šè¨­å®š ---
def get_db_connection():
    return pymysql.connect(
        host=os.getenv('DB_HOST'),
        port=int(os.getenv('DB_PORT')),
        user=os.getenv('DB_USER'), 
        password=os.getenv('DB_PASSWORD'), 
        db=os.getenv('DB_NAME'), 
        charset='utf8mb4',
        cursorclass=DictCursor
    )

HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
}
TIMEOUT = 20

def verify_single_url(url):
    """é©—è­‰å–®ä¸€ URL çš„æœ‰æ•ˆæ€§ä¸¦æå–æ¨™é¡Œ"""
    try:
        # ç°¡å–®æ¸…ç† URL å¯èƒ½å¸¶æœ‰çš„å¼•è™Ÿæˆ–ç©ºç™½
        url = url.strip().strip('"').strip("'")
        response = requests.get(url, headers=HEADERS, timeout=TIMEOUT, allow_redirects=True)
        
        if response.status_code in [200, 403]:
            text = response.text
            title_start = text.find('<title>') + 7
            title_end = text.find('</title>', title_start)
            page_title = text[title_start:title_end].strip() if title_start > 6 else "ESG News Link"
            
            return {
                "url": url,
                "is_valid": True,
                "page_title": page_title,
                "status_code": response.status_code
            }
    except Exception:
        pass
    return {"url": url, "is_valid": False, "page_title": None}

def verify_urls_batch(urls):
    """æ‰¹æ¬¡é©—è­‰ä¸¦ç¯©é¸æœ‰æ•ˆ URL"""
    valid_list = []
    for url in urls:
        if not url: continue

        try:
            res = requests.get(url, headers=HEADERS, timeout=TIMEOUT)
            if res.status_code in [200, 403]:
                valid_list.append({"url": url, "title": "Verified"})
            else:
                print(f"  âŒ ç¶²å€å¤±æ•ˆ ({res.status_code}): {url}")
        except Exception as e:
            print(f"  âŒ è«‹æ±‚éŒ¯èª¤ ({type(e).__name__}): {url}")
    return valid_list

@app.route('/')
def index():
    """
    ä¸»é è·¯ç”±ï¼šæ¸²æŸ“å„€è¡¨æ¿é¦–é 
    """
    conn = get_db_connection()
    companies_data = []
    
    try:
        # é—œéµï¼šå¼·åˆ¶åŒæ­¥è³‡æ–™åº«ç‹€æ…‹
        conn.commit()
        with conn.cursor() as cursor:
            # --- [Update] è³‡æ–™åº«è®€å–æ®µè½ (å–å¾—æ‰€æœ‰å…¬å¸) ---
            # è³‡æ–™è¡¨åç¨±è®Šæ›´: companies -> company
            # æ¬„ä½å°æ‡‰: id -> ESG_id (æˆ–å¿½ç•¥), name -> company_name, stock_id -> company_code
            # ğŸ†• åªå– analysis_status = 'completed' çš„è³‡æ–™ï¼Œæ’é™¤æ­£åœ¨åˆ†æä¸­çš„è¨˜éŒ„
            sql_companies = "SELECT * FROM company WHERE analysis_status = 'completed'"
            cursor.execute(sql_companies)
            companies_basic = cursor.fetchall()
            
            for comp in companies_basic:
                # å–å¾—é—œè¯ç”¨çš„ Key
                stock_code = comp['company_code'] # å°æ‡‰ company_report.company_id
                report_year = comp['Report_year'] # å°æ‡‰ company_report.year
                industry = comp['industry']
                
                # --- [Update] è³‡æ–™åº«è®€å–æ®µè½ (å–å¾—è©²å…¬å¸è©²å¹´åº¦æ‰€æœ‰ ESG ç´°é …) ---
                # è³‡æ–™è¡¨åç¨±è®Šæ›´: esg_details -> company_report
                # æˆ‘å€‘æ’ˆå‡ºæ‰€æœ‰æ¬„ä½ï¼ŒåŒ…å«æ–°å¢çš„ external_evidence, MSCI_flag ç­‰ï¼Œä¾›å‰ç«¯é¡¯ç¤º
                sql_details = """
                    SELECT ESG_category, SASB_topic, risk_score, adjustment_score, 
                           report_claim, page_number, greenwashing_factor,
                           external_evidence, external_evidence_url, 
                           consistency_status, MSCI_flag, is_verified
                    FROM company_report 
                    WHERE company_id = %s AND year = %s
                """
                cursor.execute(sql_details, (stock_code, report_year))
                details = cursor.fetchall()
                
                # --- Python é‹ç®—æ®µè½ (å‘¼å«è¨ˆç®—å¼•æ“) ---
                # è¨ˆç®—é‚è¼¯ä¸è®Šï¼Œä½† details å…§çš„ key è®Šäº†ï¼Œéœ€ç”± calculate_esg.py è™•ç†æˆ–åœ¨æ­¤è½‰æ›
                # é€™è£¡æˆ‘å€‘ç¶­æŒç›´æ¥å‚³å…¥ï¼Œè®“ calculate_esg.py å»é©æ‡‰æ–°çš„ key åç¨±
                scores = calculate_esg_scores(industry, details)
                
                # çµ„åˆæœ€çµ‚ç‰©ä»¶
                company_obj = {
                    'id': comp['ESG_id'],     # ä½¿ç”¨æ–°çš„ PK
                    'name': comp['company_name'],
                    'stockId': comp['company_code'],
                    'industry': comp['industry'],
                    'year': comp['Report_year'],
                    'url': comp['URL'],       # æ–°å¢: å ±å‘Šé€£çµ
                    'greenwashingScore': scores['Total'], # ç¸½é¢¨éšªåˆ†
                    'eScore': scores['E'],
                    'sScore': scores['S'],
                    'gScore': scores['G'],
                    'layer4Data': details     # å‚³éçµ¦å‰ç«¯åšè©³ç´°åˆ—è¡¨é¡¯ç¤º (åŒ…å« Layer 4 å’Œ Layer 5 æ‰€éœ€è³‡æ–™)
                }
                companies_data.append(company_obj)
                
    finally:
        conn.close()

    return render_template('index.html', companies=companies_data)


# ==================================================
# æ–°å¢: é€²åº¦æŸ¥è©¢ API
# ==================================================
@app.route('/api/check_progress/<esg_id>', methods=['GET'])
def check_progress(esg_id):
    from src.db_service import get_db_connection # ç¢ºä¿ä½¿ç”¨å¸¶æœ‰ commit/close çš„ç‰ˆæœ¬
    try:
        with get_db_connection() as conn:
            with conn.cursor() as cursor:
                # ğŸ†• åŒæ­¥è®€å–åˆ†æç‹€æ…‹ã€å…·é«”ç™¾åˆ†æ¯”èˆ‡æœ€å¾Œä¸€ç­† Log
                sql = "SELECT analysis_status FROM company WHERE ESG_id = %s"
                # sql = "SELECT analysis_status, analysis_progress, last_log FROM company WHERE ESG_id = %s"
                cursor.execute(sql, (esg_id,))
                result = cursor.fetchone()

                if not result:
                    return jsonify({"stage": "unknown", "status": "not_found"}), 404

                # ä¸é è¨­ç‚º stage1ï¼Œç›´æ¥å›å‚³è³‡æ–™åº«çœŸå¯¦ç‹€æ…‹
                current_status = result["analysis_status"] or "processing"
                # progress = result["analysis_progress"] or 0
                # log = result["last_log"] or ""
                
                response = jsonify({
                    "stage": current_status,
                    "status": "completed" if current_status == "completed" else "processing"
                })
    
                # å¼·åˆ¶å¾Œç«¯ä¸çµ¦ç€è¦½å™¨å¿«å–
                response.headers["Cache-Control"] = "no-cache, no-store, must-revalidate"
                response.headers["Pragma"] = "no-cache"
                response.headers["Expires"] = "0"
                
                return response

                #èˆŠç¨‹å¼ç¢¼
                #return jsonify({
                #    "stage": current_status,  # é€™æœƒå°æ‡‰å‰ç«¯çš„ data.stage
                #    # "progress": progress,
                #    # "last_log": log,
                #    "status": "completed" if current_status == "completed" else "processing"
                #})
    except Exception as e:
        return jsonify({"error": str(e), "status": "error"}), 500

# æ–°å¢ï¼šæŸ¥è©¢å…¬å¸ ESG è³‡æ–™çš„ API
@app.route('/api/query_company', methods=['POST'])
def query_company():
    """
    æŸ¥è©¢å…¬å¸ ESG è³‡æ–™ä¸¦è™•ç†è‡ªå‹•æŠ“å–
    
    è«‹æ±‚åƒæ•¸ï¼š
        {
            "year": 2024,
            "company_code": "2330",
            "auto_fetch": false  # æ˜¯å¦åŒæ„è‡ªå‹•æŠ“å–
        }
    
    å›æ‡‰æ ¼å¼ï¼š
        {
            "status": "completed|processing|failed|validation_needed|not_found",
            "message": "èªªæ˜è¨Šæ¯",
            "data": {...},  # è‹¥æœ‰è³‡æ–™å‰‡åŒ…å«å®Œæ•´ ESG åˆ†æçµæœ
            "esg_id": "20242330"
        }
    """
    try:
        # å»¶é²å°å…¥ä»¥é¿å…å¾ªç’°ä¾è³´æˆ–åˆå§‹åŒ–éŒ¯èª¤ï¼Œä¸¦ç¢ºä¿èƒ½è¢« try-except æ•ç²
        from src.db_service import query_company_data, insert_company_basic, update_analysis_status, insert_analysis_results
        from src.crawler_esgReport import validate_report_exists, download_esg_report
        from src.gemini_api import analyze_esg_report
        
        # è§£æè«‹æ±‚åƒæ•¸
        data = request.get_json()
        year = int(data.get('year'))
        company_code = str(data.get('company_code')).strip()
        auto_fetch = data.get('auto_fetch', False)
        
        if not year or not company_code:
            return jsonify({
                'status': 'error',
                'message': 'åƒæ•¸éŒ¯èª¤ï¼šyear å’Œ company_code ç‚ºå¿…å¡«'
            }), 400
        
        esg_id = f"{year}{company_code}"
        
        # 1. æŸ¥è©¢è³‡æ–™åº«
        result = query_company_data(year, company_code)
        
        # å¦‚æœè³‡æ–™åº«å·²å­˜åœ¨è©²å…¬å¸å¹´åº¦è³‡æ–™ï¼Œä½¿ç”¨è³‡æ–™åº«ä¸­çš„çœŸå¯¦ ESG_id (å¯èƒ½æ˜¯ C001 ç­‰èˆŠæ ¼å¼)
        if result['exists'] and result['data'] and 'ESG_id' in result['data']:
            esg_id = result['data']['ESG_id']
        
        PROCESSING_STATES = ['processing', 'stage1', 'stage2', 'stage3', 'stage4', 'stage5', 'stage6']
        should_execute = False  # ğŸ†• æ¨™è¨˜æ˜¯å¦é€²å…¥åŸ·è¡Œæµç¨‹

        # æƒ…æ³ A: completed - ç›´æ¥å›å‚³è³‡æ–™
        if result['status'] == 'completed':
            # è¨ˆç®— ESG åˆ†æ•¸ï¼ˆä½¿ç”¨ç¾æœ‰é‚è¼¯ï¼‰
            from src.calculate_esg import calculate_esg_scores
            
            company_data = result['data']
            details = result['details']
            
            scores = calculate_esg_scores(company_data['industry'], details)
            
            company_obj = {
                'id': company_data['ESG_id'],
                'name': company_data['company_name'],
                'stockId': company_data['company_code'],
                'industry': company_data['industry'],
                'year': company_data['Report_year'],
                'url': company_data['URL'],
                'greenwashingScore': scores['Total'],
                'eScore': scores['E'],
                'sScore': scores['S'],
                'gScore': scores['G'],
                'layer4Data': details
            }
            
            return jsonify({
                'status': 'completed',
                'message': 'è³‡æ–™å·²å­˜åœ¨',
                'data': company_obj,
                'esg_id': esg_id
            })
        
        # æƒ…æ³ B: processing/stageN - éœ€è¦åˆ¤æ–·æ˜¯ã€Œæ­£åœ¨åŸ·è¡Œä¸­ã€é‚„æ˜¯ã€Œä¸­æ–·éœ€è¦æ¢å¾©ã€
        elif result['status'] in PROCESSING_STATES:
            # ğŸ†• ä½¿ç”¨è¨˜æ†¶é«”æ¨™è¨˜åˆ¤æ–·æ˜¯å¦æ­£åœ¨æ´»èºè™•ç†
            if is_actively_processing(esg_id):
                # å¾Œç«¯æ­£åœ¨æ´»èºè™•ç†ä¸­ï¼Œå›å‚³ processing è®“å‰ç«¯é¡¯ç¤ºé€²åº¦æ¢
                return jsonify({
                    'status': 'processing',
                    'message': 'åˆ†æé€²è¡Œä¸­ï¼Œè«‹ç¨å€™',
                    'esg_id': esg_id
                })
            else:
                # å¾Œç«¯å·²ä¸­æ–·ï¼ˆè¨˜æ†¶é«”æ¨™è¨˜ä¸å­˜åœ¨ï¼‰ï¼Œéœ€è¦ç”¨æˆ¶é¸æ“‡
                if not auto_fetch:
                    return jsonify({
                        'status': 'resume_needed',
                        'message': f'åµæ¸¬åˆ°ä¸Šæ¬¡åˆ†æä¸­æ–·æ–¼ {result["status"]}ï¼Œæ˜¯å¦è¦å¾æ–·é»ç¹¼çºŒï¼Ÿ',
                        'current_stage': result['status'],
                        'esg_id': esg_id
                    })
                # ç”¨æˆ¶å·²åŒæ„ auto_fetchï¼Œå–å¾— report_info ä¸¦ç¹¼çºŒ
                exists, report_info = validate_report_exists(year, company_code)
                if not exists:
                    return jsonify({
                        'status': 'not_found',
                        'message': f'æŸ¥ç„¡ {year} å¹´åº¦çš„æ°¸çºŒå ±å‘Šï¼ˆå…¬å¸ä»£ç¢¼: {company_code}ï¼‰',
                        'esg_id': esg_id
                    }), 404
                # ğŸ†• è¨­ç½®æ¨™è¨˜ï¼Œé€²å…¥ä¸‹æ–¹åŸ·è¡Œæµç¨‹
                should_execute = True
        
        # æƒ…æ³ C & D: failed æˆ– not_found - éœ€è¦é©—è­‰å ±å‘Šæ˜¯å¦å­˜åœ¨
        else:
            # é©—è­‰å ±å‘Šæ˜¯å¦å­˜åœ¨
            exists, report_info = validate_report_exists(year, company_code)
            
            if not exists:
                return jsonify({
                    'status': 'not_found',
                    'message': f'æŸ¥ç„¡ {year} å¹´åº¦çš„æ°¸çºŒå ±å‘Šï¼ˆå…¬å¸ä»£ç¢¼: {company_code}ï¼‰',
                    'esg_id': esg_id
                }), 404
            
            # å ±å‘Šå­˜åœ¨ï¼Œä½†ç”¨æˆ¶å°šæœªåŒæ„è‡ªå‹•æŠ“å–
            if not auto_fetch:
                return jsonify({
                    'status': 'validation_needed',
                    'message': 'æŸ¥ç„¡è³‡æ–™ï¼Œæ˜¯å¦å•Ÿå‹•è‡ªå‹•æŠ“å–èˆ‡åˆ†æï¼Ÿ',
                    'report_info': report_info,
                    'esg_id': esg_id
                })
            
            # ğŸ†• è¨­ç½®æ¨™è¨˜ï¼Œé€²å…¥ä¸‹æ–¹åŸ·è¡Œæµç¨‹
            should_execute = True
        
        # === ç”¨æˆ¶åŒæ„è‡ªå‹•æŠ“å–ï¼Œé–‹å§‹åŸ·è¡Œæµç¨‹ ===
        # ğŸ†• åªæœ‰ç•¶ should_execute = True æ™‚æ‰æœƒç¹¼çºŒ
        if not should_execute:
            return jsonify({
                'status': 'error',
                'message': 'ç¨‹å¼æµç¨‹ç•°å¸¸ï¼Œè«‹é‡æ–°æ“ä½œ'
            }), 500
        
        # ğŸ†• å°å…¥æ–·é»çºŒå‚³å·¥å…·
        from src.recovery_utils import determine_resume_point, print_recovery_status
        
        # æª¢æŸ¥æ˜¯å¦ç‚ºé‡æ–°å•Ÿå‹•ï¼ˆè³‡æ–™å·²å­˜åœ¨ä¸”ç‹€æ…‹ç‚º failed æˆ– stageNï¼‰
        PROCESSING_STATES_FOR_RESUME = ['failed', 'stage1', 'stage2', 'stage3', 'stage4', 'stage5', 'stage6']
        is_resume = (result['status'] in PROCESSING_STATES_FOR_RESUME)
        
        if is_resume:
            # ğŸ†• æ–·é»çºŒå‚³ï¼šåˆ¤æ–·æ‡‰å¾å“ªå€‹éšæ®µç¹¼çºŒ
            recovery_info = print_recovery_status(year, company_code, result['status'])
            resume_from = recovery_info['resume_from']
            print(f"ğŸ“Œ æ–·é»çºŒå‚³æ¨¡å¼ï¼šå¾ {resume_from} ç¹¼çºŒ")
            run_analysis = True  # ğŸ†• æ¨™è¨˜éœ€è¦åŸ·è¡Œåˆ†æ
        else:
            # é¦–æ¬¡åŸ·è¡Œï¼šæ’å…¥åŸºæœ¬è³‡æ–™
            success, _, msg = insert_company_basic(
                year=year,
                company_code=company_code,
                company_name=report_info.get('company_name', ''),
                industry=report_info.get('sector', ''),  # æ·»åŠ ç”¢æ¥­é¡åˆ¥
                status='processing'
            )
            
            if not success and 'å·²å­˜åœ¨' not in msg:
                # å¦‚æœéŒ¯èª¤ä¸æ˜¯ã€Œè³‡æ–™å·²å­˜åœ¨ã€ï¼Œå‰‡å›å‚³éŒ¯èª¤
                return jsonify({
                    'status': 'error',
                    'message': f'æ’å…¥åŸºæœ¬è³‡æ–™å¤±æ•—: {msg}'
                }), 500
            
            resume_from = 'stage1'  # é¦–æ¬¡åŸ·è¡Œå¾ stage1 é–‹å§‹
            run_analysis = True  # ğŸ†• æ¨™è¨˜éœ€è¦åŸ·è¡Œåˆ†æ
        
        # === é–‹å§‹åŸ·è¡Œåˆ†ææµç¨‹ ===
        if run_analysis:
            print(f"ğŸ” DEBUG: é€²å…¥ run_analysis å€å¡Šï¼Œresume_from={resume_from}")
            # ğŸ†• æ¨™è¨˜é–‹å§‹è™•ç†ï¼ˆç”¨æ–¼å€åˆ†æ´»èºè™•ç†å’Œä¸­æ–·æ¢å¾©ï¼‰
            mark_processing_start(esg_id)
            try:
                # === Stage 1: ä¸‹è¼‰ PDF ===
                if resume_from in ['stage1']:
                    update_analysis_status(esg_id, 'stage1')
                    print("\n--- Step 1: ä¸‹è¼‰ PDF ---")
                    download_success, pdf_path_or_error = download_esg_report(year, company_code)
                    
                    if not download_success:
                        # ä¸‹è¼‰å¤±æ•—ï¼Œæ›´æ–°ç‹€æ…‹ç‚º failed
                        update_analysis_status(esg_id, 'failed')
                        mark_processing_end(esg_id)  # ğŸ†• æ¨™è¨˜è™•ç†çµæŸ
                        return jsonify({
                            'status': 'failed',
                            'message': f'ä¸‹è¼‰å¤±æ•—: {pdf_path_or_error}',
                            'esg_id': esg_id
                        }), 500
                    
                    pdf_path = pdf_path_or_error
                else:
                    # ğŸ†• è·³éå·²å®Œæˆçš„éšæ®µï¼Œå–å¾—å·²å­˜åœ¨çš„ PDF è·¯å¾‘
                    from src.recovery_utils import check_pdf_exists
                    _, pdf_path = check_pdf_exists(year, company_code)
                    print(f"â­ï¸ Stage 1 å·²å®Œæˆï¼Œè·³éï¼ˆPDF: {pdf_path}ï¼‰")
                
                # === Stage 2: å¹³è¡ŒåŸ·è¡Œ Word Cloud å’Œ AI åˆ†æ ===
                if resume_from in ['stage1', 'stage2']:
                    import threading
                    
                    # å„²å­˜çµæœçš„è®Šæ•¸
                    wordcloud_result = None
                    analysis_result = None
                    
                    def run_wordcloud():
                        """Word Cloud ç”ŸæˆåŸ·è¡Œç·’"""
                        nonlocal wordcloud_result
                        try:
                            from src.word_cloud import generate_wordcloud
                            wordcloud_result = generate_wordcloud(year, company_code, pdf_path, force_regenerate=False)
                        except Exception as e:
                            wordcloud_result = {'success': False, 'error': str(e)}
                            print(f"âš ï¸ Word Cloud ç”ŸæˆéŒ¯èª¤: {e}")
                    
                    def run_ai_analysis():
                        """AI åˆ†æåŸ·è¡Œç·’"""
                        nonlocal analysis_result
                        try:
                            analysis_result = analyze_esg_report(
                                pdf_path, 
                                year, 
                                company_code,
                                company_name=report_info.get('company_name', ''),
                                industry=report_info.get('sector', '')
                            )
                        except Exception as e:
                            raise  # AI åˆ†æå¤±æ•—å‰‡æ•´å€‹æµç¨‹å¤±æ•—
                    
                    # å»ºç«‹ä¸¦å•Ÿå‹•åŸ·è¡Œç·’
                    wordcloud_thread = threading.Thread(target=run_wordcloud, name="WordCloudThread")
                    ai_thread = threading.Thread(target=run_ai_analysis, name="AIAnalysisThread")
                    
                    print("\n--- Step 2: AI åˆ†æ ---")
                    print("ğŸš€ å•Ÿå‹•å¹³è¡Œè™•ç†ï¼šWord Cloud èˆ‡ AI åˆ†æ")
                    update_analysis_status(esg_id, 'stage2')
                    wordcloud_thread.start()
                    ai_thread.start()
                    
                    # ç­‰å¾…å®Œæˆ
                    wordcloud_thread.join(timeout=120)  # Word Cloud æœ€å¤šç­‰ 2 åˆ†é˜
                    ai_thread.join()  # AI åˆ†æå¿…é ˆå®Œæˆ
                    
                    # è™•ç† Word Cloud çµæœï¼ˆéå¿…è¦ï¼Œå¤±æ•—ä¸å½±å“ä¸»æµç¨‹ï¼‰
                    if wordcloud_result and wordcloud_result.get('success'):
                        if wordcloud_result.get('skipped'):
                            print(f"â„¹ï¸ Word Cloud å·²å­˜åœ¨ï¼Œè·³éç”Ÿæˆ")
                        else:
                            print(f"âœ… Word Cloud ç”ŸæˆæˆåŠŸ: {wordcloud_result.get('word_count', 0)} å€‹é—œéµå­—")
                    else:
                        error_msg = wordcloud_result.get('error') if wordcloud_result else 'timeout'
                        print(f"âš ï¸ Word Cloud ç”Ÿæˆå¤±æ•—: {error_msg}ï¼ˆä¸å½±éŸ¿ä¸»æµç¨‹ï¼‰")
                else:
                    # ğŸ†• è·³é Stage 2
                    analysis_result = {'url': ''}  # ä½”ä½ï¼Œå¾ŒçºŒæœƒå¾ report_info å–å¾— URL
                    print(f"â­ï¸ Stage 2 å·²å®Œæˆï¼Œè·³é AI åˆ†æ")
                
                # === Stage 3: æ–°èçˆ¬èŸ²é©—è­‰ ===
                if resume_from in ['stage1', 'stage2', 'stage3']:
                    print("\n--- Step 3: æ–°èçˆ¬èŸ²é©—è­‰ ---")
                    update_analysis_status(esg_id, 'stage3')
                    try:
                        from src.crawler_news import search_news_for_report
                        
                        news_result = search_news_for_report(
                            year=year,
                            company_code=company_code,
                            force_regenerate=True
                        )
                        
                        if news_result['success']:
                            if news_result.get('skipped'):
                                print(f"â„¹ï¸ æ–°èè³‡æ–™å·²å­˜åœ¨ï¼Œè·³éç”Ÿæˆ")
                            else:
                                print(f"âœ… æ–°èçˆ¬èŸ²å®Œæˆï¼š{news_result['news_count']} å‰‡æ–°è")
                                print(f"   è™•ç†é …ç›®: {news_result['processed_items']}")
                                print(f"   å¤±æ•—é …ç›®: {news_result['failed_items']}")
                        else:
                            print(f"âš ï¸ æ–°èçˆ¬èŸ²å¤±æ•—ï¼š{news_result.get('error')}ï¼ˆä¸å½±éŸ¿ä¸»æµç¨‹ï¼‰")
                    except Exception as e:
                        print(f"âš ï¸ æ–°èçˆ¬èŸ²ç™¼ç”ŸéŒ¯èª¤: {str(e)}ï¼ˆä¸å½±éŸ¿ä¸»æµç¨‹ï¼‰")
                else:
                    print(f"â­ï¸ Stage 3 å·²å®Œæˆï¼Œè·³éæ–°èçˆ¬èŸ²")
                
                # === Stage 4: AI é©—è­‰èˆ‡è©•åˆ†èª¿æ•´ ===
                if resume_from in ['stage1', 'stage2', 'stage3', 'stage4']:
                    print("\n--- Step 4: AI é©—è­‰èˆ‡è©•åˆ†èª¿æ•´ ---")
                    update_analysis_status(esg_id, 'stage4')
                    try:
                        from src.run_prompt2_gemini import verify_esg_with_news
                        
                        verify_result = verify_esg_with_news(
                            year=year,
                            company_code=company_code,
                            force_regenerate=True
                        )
                        
                        if verify_result['success']:
                            if verify_result.get('skipped'):
                                print(f"â„¹ï¸ AI é©—è­‰çµæœå·²å­˜åœ¨ï¼Œè·³éç”Ÿæˆ")
                            else:
                                stats = verify_result['statistics']
                                print(f"âœ… AI é©—è­‰å®Œæˆ")
                                print(f"   è¼¸å‡ºæª”æ¡ˆ: {verify_result['output_path']}")
                                print(f"   è™•ç†é …ç›®: {stats['processed_items']}")
                                print(f"   Token ä½¿ç”¨: {stats['total_tokens']:,} (è¼¸å…¥: {stats['input_tokens']:,}, è¼¸å‡º: {stats['output_tokens']:,})")
                                print(f"   åŸ·è¡Œæ™‚é–“: {stats['api_time']:.2f} ç§’")
                        else:
                            print(f"âš ï¸ AI é©—è­‰å¤±æ•—ï¼š{verify_result.get('error')}ï¼ˆä¸å½±éŸ¿ä¸»æµç¨‹ï¼‰")
                    except Exception as e:
                        print(f"âš ï¸ AI é©—è­‰ç™¼ç”ŸéŒ¯èª¤: {str(e)}ï¼ˆä¸å½±éŸ¿ä¸»æµç¨‹ï¼‰")
                else:
                    print(f"â­ï¸ Stage 4 å·²å®Œæˆï¼Œè·³é AI é©—è­‰")
                
                # === Stage 5: ä¾†æºå¯é åº¦é©—è­‰ ===
                if resume_from in ['stage1', 'stage2', 'stage3', 'stage4', 'stage5']:
                    print("\n--- Step 5: ä¾†æºå¯é åº¦é©—è­‰ ---")
                    update_analysis_status(esg_id, 'stage5')
                    try:
                        from src.pplx_api import verify_evidence_sources
                        
                        pplx_result = verify_evidence_sources(
                            year=year,
                            company_code=company_code,
                            force_regenerate=True
                        )
                        
                        if pplx_result['success']:
                            if pplx_result.get('skipped'):
                                print(f"â„¹ï¸ ä¾†æºé©—è­‰çµæœå·²å­˜åœ¨ï¼Œè·³éç”Ÿæˆ")
                            else:
                                stats = pplx_result['statistics']
                                print(f"âœ… ä¾†æºé©—è­‰å®Œæˆ")
                                print(f"   è¼¸å‡ºæª”æ¡ˆ: {pplx_result['output_path']}")
                                print(f"   è¼¸å…¥é …ç›®: {stats['total_input']}")
                                print(f"   è¼¸å‡ºé …ç›®: {stats['total_output']}")
                                print(f"   æœ‰æ•ˆ URL: {stats['verified_count']}")
                                print(f"   æ›´æ–° URL: {stats['updated_count']}")
                                print(f"   å¤±æ•—é …ç›®: {stats['failed_count']}")
                                print(f"   åŸ·è¡Œæ™‚é–“: {stats['execution_time']:.2f} ç§’")
                        else:
                            print(f"âš ï¸ ä¾†æºé©—è­‰å¤±æ•—ï¼š{pplx_result.get('error')}ï¼ˆä¸å½±éŸ¿ä¸»æµç¨‹ï¼‰")
                    except Exception as e:
                        print(f"âš ï¸ ä¾†æºé©—è­‰ç™¼ç”ŸéŒ¯èª¤: {str(e)}ï¼ˆä¸å½±éŸ¿ä¸»æµç¨‹ï¼‰")
                else:
                    print(f"â­ï¸ Stage 5 å·²å®Œæˆï¼Œè·³éä¾†æºé©—è­‰")
                
                # Step 7: è®€å– P3 JSON ä¸¦æ’å…¥åˆ†æçµæœè‡³è³‡æ–™åº«
                print("\n--- Step 7: å­˜å…¥è³‡æ–™åº« ---")
                update_analysis_status(esg_id, 'stage6')
                import json
                
                # è®€å– P3 JSONï¼ˆæœ€çµ‚åˆ†æçµæœï¼‰
                p3_path = os.path.join(PATHS['P3_JSON'], f'{year}_{company_code}_p3.json')
                
                if os.path.exists(p3_path):
                    with open(p3_path, 'r', encoding='utf-8') as f:
                        final_analysis_items = json.load(f)
                    print(f"ğŸ“‚ è¼‰å…¥ P3 JSON: {len(final_analysis_items)} ç­†åˆ†æé …ç›®")
                else:
                    # P3 ä¸å­˜åœ¨ï¼Œæ›´æ–°ç‹€æ…‹ç‚º failed
                    print(f"âŒ P3 JSON ä¸å­˜åœ¨: {p3_path}")
                    update_analysis_status(esg_id, 'failed')
                    return jsonify({
                        'status': 'failed',
                        'message': f'åˆ†ææµç¨‹æœªå®Œæˆï¼šæ‰¾ä¸åˆ° P3 JSON æª”æ¡ˆ ({p3_path})ã€‚è«‹ç¢ºèª Step 5 (AI é©—è­‰èˆ‡è©•åˆ†èª¿æ•´) å’Œ Step 6 (ä¾†æºå¯é åº¦é©—è­‰) å·²æˆåŠŸåŸ·è¡Œã€‚',
                        'esg_id': esg_id
                    }), 500
                
                # æå–åŸºæœ¬è³‡è¨Š
                company_name = report_info.get('company_name', '')
                industry = report_info.get('sector', '')
                report_url = analysis_result.get('url', f"https://mops.twse.com.tw/mops/web/t100sb07_{year}")
                
                insert_success, insert_msg = insert_analysis_results(
                    esg_id=esg_id,
                    company_name=company_name,
                    industry=industry,
                    url=report_url,
                    analysis_items=final_analysis_items
                )
                
                if not insert_success:
                    update_analysis_status(esg_id, 'failed')
                    return jsonify({
                        'status': 'failed',
                        'message': f'æ’å…¥åˆ†æçµæœå¤±æ•—: {insert_msg}',
                        'esg_id': esg_id
                    }), 500
                
                # Step 8: æ›´æ–°ç‹€æ…‹ç‚º completed
                update_analysis_status(esg_id, 'completed')
                
                # Step 9: æŸ¥è©¢å®Œæ•´è³‡æ–™ä¸¦å›å‚³
                final_result = query_company_data(year, company_code)
                
                if final_result['status'] == 'completed':
                    from src.calculate_esg import calculate_esg_scores
                    
                    company_data = final_result['data']
                    details = final_result['details']
                    scores = calculate_esg_scores(company_data['industry'], details)
                    
                    company_obj = {
                        'id': company_data['ESG_id'],
                        'name': company_data['company_name'],
                        'stockId': company_data['company_code'],
                        'industry': company_data['industry'],
                        'year': company_data['Report_year'],
                        'url': company_data['URL'],
                        'greenwashingScore': scores['Total'],
                        'eScore': scores['E'],
                        'sScore': scores['S'],
                        'gScore': scores['G'],
                        'layer4Data': details
                    }
                    
                    # ğŸ†• åœ¨é€™è£¡åŸ·è¡Œçµ±ä¸€æ¸…ç†
                    cleanup_temp_files(year, company_code, company_name)
                    # ğŸ†• æ¨™è¨˜è™•ç†çµæŸ
                    mark_processing_end(esg_id)
                    return jsonify({
                        'status': 'completed',
                        'message': 'è‡ªå‹•æŠ“å–èˆ‡åˆ†æå®Œæˆ',
                        'data': company_obj,
                        'esg_id': esg_id
                    })
                else:
                    return jsonify({
                        'status': 'error',
                        'message': 'åˆ†æå®Œæˆä½†è³‡æ–™æŸ¥è©¢å¤±æ•—',
                        'esg_id': esg_id
                    }), 500
            
            except Exception as e:
                # ç™¼ç”ŸéŒ¯èª¤ï¼Œæ›´æ–°ç‹€æ…‹ç‚º failed
                update_analysis_status(esg_id, 'failed')
                # ğŸ†• æ¨™è¨˜è™•ç†çµæŸ
                mark_processing_end(esg_id)
                return jsonify({
                    'status': 'failed',
                    'message': f'è™•ç†éç¨‹ç™¼ç”ŸéŒ¯èª¤: {str(e)}',
                    'esg_id': esg_id
                }), 500
        else:
            # ğŸ†• run_analysis ç‚º False çš„æƒ…æ³ï¼ˆä¸æ‡‰è©²ç™¼ç”Ÿï¼‰
            return jsonify({
                'status': 'error',
                'message': 'ç¨‹å¼æµç¨‹ç•°å¸¸ï¼šæœªèƒ½é€²å…¥åˆ†ææµç¨‹',
                'esg_id': esg_id
            }), 500
    
    except Exception as e:
        return jsonify({
            'status': 'error',
            'message': f'ç³»çµ±éŒ¯èª¤: {str(e)}'
        }), 500

# Serve word cloud JSON files
@app.route('/word_cloud/wc_output/<filename>')
def serve_wordcloud(filename):
    return send_from_directory(PATHS['WORD_CLOUD_OUTPUT'], filename)

# å¦‚æœéœ€è¦ API æ ¼å¼ (Optional)
@app.route('/api/companies')
def api_companies():
    pass

if __name__ == '__main__':
    app.run(debug=True, port=5000)