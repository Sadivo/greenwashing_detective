import json
import requests
import os
import sys
from dotenv import load_dotenv
from perplexity import Perplexity
import glob
import time
from urllib.parse import urlparse

load_dotenv()

# å°å…¥é›†ä¸­é…ç½®
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
from config import PATHS

HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
}
TIMEOUT = 20

def is_official_site(url, company_name):
    """
    ç°¡å–®åˆ¤æ–·ç¶²å€æ˜¯å¦ç‚ºå…¬å¸å®˜ç¶²
    """
    parsed_url = urlparse(url)
    domain = parsed_url.netloc.lower()
    # ç§»é™¤å…¬å¸åç¨±ä¸­çš„å¸¸è¦‹å¾Œç¶´ä»¥ä¾¿æ¯”å°
    clean_name = company_name.lower().replace("è‚¡ä»½æœ‰é™å…¬å¸", "").replace("corp", "").replace("inc", "").strip()
    
    # åˆ¤æ–·ç¶²åŸŸæ˜¯å¦åŒ…å«å…¬å¸åç¨±é—œéµå­—
    if clean_name in domain:
        return True
    return False

def verify_single_url(url):
    """é©—è­‰å–®ä¸€ URL çš„æœ‰æ•ˆæ€§ä¸¦æå–æ¨™é¡Œ"""
    try:
        if not url or not url.startswith('http'):
            return {"url": url, "is_valid": False, "page_title": None}
            
        url = url.strip().strip('"').strip("'")
        response = requests.get(url, headers=HEADERS, timeout=TIMEOUT, allow_redirects=True)
        
        if response.status_code in [200, 403]:
            text = response.text
            title_start = text.find('<title>') + 7
            title_end = text.find('</title>', title_start)
            page_title = text[title_start:title_end].strip() if title_start > 6 else "ESG Evidence"
            
            return {
                "url": url,
                "is_valid": True,
                "page_title": page_title,
                "status_code": response.status_code
            }
    except Exception as e:
        print(f"  âŒ é©—è­‰éŒ¯èª¤ ({type(e).__name__}): {url}")
    return {"url": url, "is_valid": False, "page_title": None}


def search_with_perplexity(query, company_name):
    """ä½¿ç”¨ Perplexity æœå°‹ï¼Œä¸¦æ’é™¤å®˜ç¶²"""
    try:
        perplexity_client = Perplexity(api_key=os.environ.get("PERPLEXITY_API_KEY"))
        # å¼·åŒ– Promptï¼šæ˜ç¢ºè¦æ±‚æ’é™¤å®˜æ–¹ç¶²ç«™ï¼Œå°‹æ‰¾ç¬¬ä¸‰æ–¹æ–°èæˆ–å ±å‘Š
        prompt = (
            f"æä¾›é—œæ–¼ã€Œ{query}ã€çš„1å€‹å¯é ç¬¬ä¸‰æ–¹è³‡è¨Šä¾†æºç¶²å€ï¼Œè«‹å‹™å¿…æ’é™¤ã€Œ{company_name}ã€çš„å®˜æ–¹ç¶²ç«™æˆ–å®˜æ–¹åŸŸåçš„ç¶²å€ï¼Œåƒ…è¼¸å‡ºJSONæ ¼å¼ï¼š{{\"urls\": [\"url1\"]}}"
        )
        
        response = perplexity_client.chat.completions.create(
            model="sonar",
            messages=[{"role": "user", "content": prompt}]
        )
        
        usage = response.usage
        print(f"Perplexity API: Input={usage.prompt_tokens}, Output={usage.completion_tokens}, Total={usage.total_tokens}")

        content = response.choices[0].message.content
        clean_json = content.replace('```json', '').replace('```', '').strip()
        result = json.loads(clean_json)
        return result.get('urls', [])
    except Exception as e:
        print(f"Perplexity å¤±æ•—: {e}")
        return []

def find_alternative_url(company, year, evidence_summary, original_url):
    """å°‹æ‰¾æ›¿ä»£çš„æœ‰æ•ˆç¬¬ä¸‰æ–¹ URL"""
    search_query = f"{company} {year} ESG {evidence_summary[:50]}"
    print(f"  ğŸ” æœå°‹æ›¿ä»£ URL (æ’é™¤å®˜ç¶²): {search_query}")

    pplx_urls = search_with_perplexity(search_query, company)
    for url in pplx_urls:
        # æª¢æŸ¥æ˜¯å¦ç‚ºå®˜æ–¹ç¶²ç«™
        if is_official_site(url, company):
            print(f"  âš ï¸ åµæ¸¬åˆ°ç‚ºå®˜ç¶²ï¼Œè·³é: {url}")
            continue
            
        verification = verify_single_url(url)
        if verification["is_valid"]:
            print(f"  âœ… Perplexity æ‰¾åˆ°æœ‰æ•ˆç¬¬ä¸‰æ–¹ URL: {url}")
            return url
    
    return None # è‹¥æ‰¾ä¸åˆ°å‰‡å›å‚³ None

def verify_evidence_sources(year, company_code, force_regenerate=False):
    """
    é©—è­‰ ESG åˆ†æå¤–éƒ¨è­‰æ“šä¾†æºçš„å¯é åº¦
    
    é€™æ˜¯ T5 æ•´åˆçš„æ¨¡çµ„åŒ–æ¥å£å‡½æ•¸ï¼Œç”¨æ–¼ app.py Step 6
    
    åƒæ•¸:
        year (int): å ±å‘Šå¹´åº¦
        company_code (str): å…¬å¸ä»£ç¢¼
        force_regenerate (bool): æ˜¯å¦å¼·åˆ¶é‡æ–°é©—è­‰ï¼Œé è¨­ False
    
    è¿”å›:
        dict: {
            'success': bool,
            'message': str,
            'output_path': str,
            'skipped': bool,
            'statistics': {
                'processed_items': int,
                'verified_count': int,
                'updated_count': int,
                'failed_count': int,
                'perplexity_calls': int,
                'execution_time': float
            },
            'error': str  # è‹¥å¤±æ•—
        }
    """
    start_time = time.perf_counter()
    
    try:
        # 1. æ§‹å»ºæª”æ¡ˆè·¯å¾‘
        input_folder = PATHS['P2_JSON']
        output_folder = PATHS['P3_JSON']
        os.makedirs(output_folder, exist_ok=True)
        
        input_file = os.path.join(input_folder, f'{year}_{company_code}_p2.json')
        output_file = os.path.join(output_folder, f'{year}_{company_code}_p3.json')
        
        # 2. æª¢æŸ¥è¼¸å…¥æª”æ¡ˆæ˜¯å¦å­˜åœ¨
        if not os.path.exists(input_file):
            return {'success': False, 'message': f'è¼¸å…¥æª”æ¡ˆä¸å­˜åœ¨: {input_file}', 'error': 'Input file not found'}
        
        # 3. æª¢æŸ¥è¼¸å‡ºæª”æ¡ˆæ˜¯å¦å·²å­˜åœ¨
        if os.path.exists(output_file) and not force_regenerate:
            return {'success': True, 'message': 'ä¾†æºé©—è­‰çµæœå·²å­˜åœ¨', 'output_path': output_file, 'skipped': True, 'statistics': {'execution_time': time.perf_counter() - start_time}}
        
        # 4. è®€å– P2 JSON
        print(f"ğŸ“– è®€å–æª”æ¡ˆ: {input_file}")
        with open(input_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        processed_data = [] # ç”¨æ–¼å­˜å„²æœ‰æ•ˆçš„çµæœ
        verified_count = 0
        updated_count = 0
        failed_count = 0
        perplexity_calls = 0
        
        print(f"\né–‹å§‹é©—è­‰è³‡æ–™...\n")
        
        # 5. é€ç­†é©—è­‰ URL
        for idx, item in enumerate(data, 1):
            url = item.get("external_evidence_url", "").strip()
            company = item.get("company", "")
            year_str = item.get("year", "")
            evidence = item.get("external_evidence", "")
            
            # --- éœ€æ±‚ 1: æ²’ç¶²å€ç›´æ¥è·³é ---
            if not url:
                print(f"[{idx}] â­ï¸ é …ç›®ç„¡ç¶²å€ï¼Œç›´æ¥è·³é")
                continue

            print(f"[{idx}] è™•ç†: {company} {year_str} - {item.get('esg_category')}")
            
            # é©—è­‰åŸå§‹ URL
            verification = verify_single_url(url)
            
            if verification["is_valid"]:
                print(f"  âœ… URL æœ‰æ•ˆ")
                verified_count += 1
                item["is_verified"] = "True"
                processed_data.append(item)
            else:
                print(f"  âŒ URL å¤±æ•ˆï¼Œå°‹æ‰¾æ›¿ä»£ç¬¬ä¸‰æ–¹ä¾†æº...")
                perplexity_calls += 1
                new_url = find_alternative_url(company, year_str, evidence, url)
                
                if new_url:
                    item["external_evidence_url"] = new_url
                    item["is_verified"] = "True"
                    updated_count += 1
                    processed_data.append(item)
                    print(f"  ğŸ”„ å·²æ›´æ–°ç‚ºç¬¬ä¸‰æ–¹ URL")
                else:
                    failed_count += 1
                    print(f"  âš ï¸ ç„¡æ³•æ‰¾åˆ°æ›¿ä»£ä¾†æºï¼Œæ­¤é …ä¸ç”¢å‡º")
            
        # 6. å¯«å…¥ P3 JSON (åƒ…åŒ…å« processed_data)
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(processed_data, f, ensure_ascii=False, indent=2)
        
        return {
            'success': True,
            'message': 'ä¾†æºé©—è­‰å®Œæˆ',
            'output_path': output_file,
            'statistics': {
                'processed_items': len(processed_data),
                'verified_count': verified_count,
                'updated_count': updated_count,
                'failed_count': failed_count,
                'execution_time': time.perf_counter() - start_time
            }
        }
    except Exception as e:
        return {'success': False, 'message': f'é©—è­‰å¤±æ•—: {str(e)}', 'error': str(e)}

def process_json_file(input_file, output_file):
    """è™•ç† JSON æª”æ¡ˆä¸­çš„æ‰€æœ‰ URL (CLI ç›´æ¥åŸ·è¡Œç‰ˆæœ¬)"""
    with open(input_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    processed_data = []
    for item in data:
        url = item.get("external_evidence_url", "").strip()
        company = item.get("company", "")
        year = item.get("year", "")
        evidence = item.get("external_evidence", "")
        
        if not url:
            continue
            
        verification = verify_single_url(url)
        if verification["is_valid"]:
            item["is_verified"] = "True"
            processed_data.append(item)
        else:
            new_url = find_alternative_url(company, year, evidence, url)
            if new_url:
                item["external_evidence_url"] = new_url
                item["is_verified"] = "True"
                processed_data.append(item)
    
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(processed_data, f, ensure_ascii=False, indent=2)

def get_latest_file(folder_path, extension=".json"):
    files = glob.glob(os.path.join(folder_path, f"*{extension}"))
    return max(files, key=os.path.getmtime) if files else None

if __name__ == "__main__":
    # (time-1) è¨˜éŒ„ç¨‹å¼é–‹å§‹çš„æœ€æ—©æ™‚é–“é»
    script_start_time = time.perf_counter()

    # 1. è·¯å¾‘è¨­å®š
    INPUT_FOLDER = PATHS['P2_JSON']
    OUTPUT_FOLDER = PATHS['P3_JSON']
    os.makedirs(OUTPUT_FOLDER, exist_ok=True)

    # 2. æŠ“å–æœ€æ–°æª”æ¡ˆ
    latest_path = get_latest_file(INPUT_FOLDER)
    if latest_path:
        # 3. è®€å–å…§å®¹ä»¥ç²å–å‹•æ…‹å‘½åè³‡è¨Š
        try:
            with open(latest_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            # å–å¾—å…¬å¸èˆ‡å¹´ä»½ (ç§»é™¤ç©ºæ ¼ä»¥é˜²æª”åå‡ºéŒ¯)
            first_item = data[0] if isinstance(data, list) and data else {}
            company = str(first_item.get("company", "Unknown")).replace(" ", "")
            year = str(first_item.get("year", "Unknown")).replace(" ", "")

            # 4. ç²¾ç°¡å®šç¾©è¼¸å‡ºè·¯å¾‘
            # ç›´æ¥åœ¨å‘¼å«å‡½å¼æ™‚çµ„åˆè·¯å¾‘èˆ‡æª”å
            output_file = f"{OUTPUT_FOLDER}/{year}_{company}_p3.json"
            
            # 5. åŸ·è¡Œæ ¸å¿ƒé©—è­‰é‚è¼¯
            process_json_file(latest_path, output_file)
            print(f"â±ï¸ åŸ·è¡Œç¸½è€—æ™‚: {time.perf_counter() - script_start_time:.2f} ç§’")
        except Exception as e:
            print(f"âŒ éŒ¯èª¤: {e}")